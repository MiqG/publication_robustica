"""
Workflow purpose
----------------
Evaluate the performance impact of changing the algorithm.

Outline
-------
1. Cluster 100 ICA runs and cluster:
    - the default algorithm (Icasso): 
        1) Distance Matrix
        2) Agglomerative clustering
        3) Compute centroids
        
    - robustica without sign correction
        1) Agglomerative clustering
        2) Compute centroids
    
    - robustica
        1) Correct signs
        2) Agglomerative clustering
        3) Compute centroids
    
    - robustica + PCA
        1) Correct signs
        2) compress feature space: PCA
        3) Agglomerative clustering
        4) Compute centroids
        
2. make figures
"""

import os

##### VARIABLES #####
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
DATA_DIR = os.path.join(ROOT,'data')
RAW_DIR = os.path.join(DATA_DIR,'raw')
PREP_DIR = os.path.join(DATA_DIR,'prep')
RESULTS_DIR = os.path.join(ROOT,'results','benchmark_sign_inference')

ALGORITHMS = ['icasso','robustica_nosign','robustica','robustica_pca']
ITERATIONS = 100
DATASETS = ['Sastry2019']
N_COMPONENTS = {
    'Sastry2019': 100
}

##### RULES #####
rule all:
    input:
        # evaluate performance
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),dataset=DATASETS),
        
        # make figures
        expand(os.path.join(RESULTS_DIR,'figures','{dataset}'),dataset=DATASETS)
        
        
rule evaluate_performance:
    input:
        S = os.path.join(PREP_DIR,'ica_runs','{dataset}','S.pickle.gz'),
        A = os.path.join(PREP_DIR,'ica_runs','{dataset}','A.pickle.gz'),
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz')
    params:
        algorithms = ','.join(ALGORITHMS),
        iterations = ITERATIONS
    shell:
        """
        python scripts/evaluate_performance.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --output_file={output} \
                    --iterations={params.iterations} \
                    --algorithms={params.algorithms}
        """

formatted = {
    'S_stds' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S_std.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'Ss' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'As' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-A.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS]
}
rule figures_benchmark_performance:
    input:
        performance_evaluation = os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),
        clustering_info = os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz'),
        S_stds = formatted['S_stds'],
        Ss = formatted['Ss'],
        As = formatted['As']
    output:
        figs_dir = directory(os.path.join(RESULTS_DIR,'figures','{dataset}'))
    params:
        S_stds = ','.join(formatted['S_stds']),
        Ss = ','.join(formatted['Ss']),
        As = ','.join(formatted['As']),
        files_dir = directory(os.path.join(RESULTS_DIR,'files','{dataset}'))
    shell:
        """
        Rscript scripts/figures_benchmark_sign_inference.R \
                    --performance_evaluation_file={input.performance_evaluation} \
                    --clustering_info_file={input.clustering_info} \
                    --S_stds_files={params.S_stds} \
                    --Ss_files={params.Ss} \
                    --As_files={params.As} \
                    --files_dir={params.files_dir} \
                    --figs_dir={output}
        """
        