"""
Workflow purpose
----------------
Evaluate the performance impact of changing the algorithm.

Outline
-------
1. Cluster 100 ICA runs and cluster:
    - the default algorithm (Icasso): 
        1) Distance Matrix
        2) Agglomerative clustering
        3) Compute centroids
        
    - robustica without sign correction
        1) Agglomerative clustering
        2) Compute centroids
    
    - robustica
        1) Correct signs
        2) Agglomerative clustering
        3) Compute centroids
    
    - robustica + PCA
        1) Correct signs
        2) compress feature space: PCA
        3) Agglomerative clustering
        4) Compute centroids
        
2. make figures
"""

import os

##### VARIABLES #####
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
DATA_DIR = os.path.join(ROOT,'data')
RAW_DIR = os.path.join(DATA_DIR,'raw')
PREP_DIR = os.path.join(DATA_DIR,'prep')
RESULTS_DIR = os.path.join(ROOT,'results','benchmark_sign_inference')
SAVE_PARAMS = {"sep": "\t", "index": False, "compression": "gzip"}

ALGORITHMS = ['icasso','icasso_infer_signs','icasso_pca','icasso_pca_nosign',
              'robustica_nosign','robustica','robustica_pca']
ITERATIONS = 100
N_COMPONENTS = 100

CANCER_TYPES = [
    'BRCA',
    'KIRC',
    'LUAD',
    'LUSC',
    'OV',
    'HNSC',
    'GBM',
    'UCEC',
    'THCA',
    'PRAD',
    'COAD',
    'LGG',
    'STAD',
    'SKCM',
    'LIHC',
    'BLCA',
    'KIRP',
    'CESC',
    'SARC',
    'ESCA',
    'LAML' 
]

TISSUE_TYPES = [
    'blood',
    'brain', 
    'skin',
    'esophagus',
    'blood_vessel',
    'adipose_tissue', 
    'heart',
    'muscle',
    'lung',
    'colon', 
    'thyroid',
    'nerve',
    'breast',
    'testis',
    'stomach', 
    'pancreas', 
    'pituitary',
    'adrenal_gland', 
    'prostate', 
    'spleen',
    'liver'
]

DATASETS = CANCER_TYPES + TISSUE_TYPES + ['Sastry2019']

##### RULES #####
rule all:
    input:
        # evaluate performance
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'), dataset=DATASETS),
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_mean.tsv.gz'), dataset=DATASETS),
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_std.tsv.gz'), dataset=DATASETS),

        # evaluate module mapping
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz'), dataset=DATASETS),
        
        # evaluate module mapping robustness
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-module_mapping_robustness.tsv.gz'), dataset=DATASETS, algorithm=['icasso','robustica_pca']),
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_robustness.tsv.gz'), dataset=DATASETS),

        # merge results
        os.path.join(RESULTS_DIR,'files','merged_clustering_performance_evaluation.tsv.gz'),
        os.path.join(RESULTS_DIR,'files','merged_clustering_info.tsv.gz'),
        os.path.join(RESULTS_DIR,'files','merged_module_mapping_evaluation.tsv.gz'),
        os.path.join(RESULTS_DIR,'files','merged_module_mapping_robustness.tsv.gz'),
        os.path.join(RESULTS_DIR,'files','merged_summary_S_mean.tsv.gz'),
        os.path.join(RESULTS_DIR,'files','merged_summary_S_std.tsv.gz'),
        # make figures
        #expand(os.path.join(RESULTS_DIR,'figures','{dataset}'),dataset=DATASETS)
        
# outputs rule below
formatted = {
    'S_means' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'S_stds' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S_std.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'A_means' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-A.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'A_stds' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-A_std.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS]
}
rule evaluate_performance:
    input:
        S = os.path.join(PREP_DIR,'ica_runs','{dataset}','S.pickle.gz'),
        A = os.path.join(PREP_DIR,'ica_runs','{dataset}','A.pickle.gz'),
    output:
        formatted['S_means'],
        formatted['S_stds'],
        formatted['A_means'],
        formatted['A_stds'],
        os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz'),
        perf_eval = os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz')
    params:
        algorithms = ','.join(ALGORITHMS),
        iterations = ITERATIONS
    resources:
        runtime = 3600*24, # 24h
        memory = 60 # GB
    shell:
        """
        nice python scripts/evaluate_performance.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --output_file={output.perf_eval} \
                    --iterations={params.iterations} \
                    --algorithms={params.algorithms}
        """


rule summary_stats_from_robust_matrices:
    input:
        S_means = formatted['S_means'],
        S_stds = formatted['S_stds']
    output:
        S_means = os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_mean.tsv.gz'),
        S_stds = os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_std.tsv.gz')
    params:
        algorithms = ALGORITHMS
    run:
        import os
        import pandas as pd
        
        for key, filenames in input.items():
            dfs = []
            for f in filenames:
                algorithm = os.path.basename(f).replace("-S_std.tsv.gz","").replace("-S.tsv.gz","")
                print(algorithm)

                S_std = pd.read_table(f, index_col=0)
                df = S_std.mean(axis=0).reset_index().rename(columns={"index":"cluster_id", 0:"cluster_avg_std"})
                df["algorithm"] = algorithm
                dfs.append(df)

            dfs = pd.concat(dfs)
        
            # save
            dfs.to_csv(output[key], sep="\t", index=False, compression="gzip")
        
        print("Done!")
            

rule evaluate_module_mapping:
    input:
        S = os.path.join(PREP_DIR,'ica_runs','{dataset}','S.pickle.gz'),
        A = os.path.join(PREP_DIR,'ica_runs','{dataset}','A.pickle.gz'),
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz')
    params:
        algorithms = ','.join(['icasso','robustica_pca']),
        iterations = ITERATIONS,
        n_components = N_COMPONENTS
    resources:
        runtime = 3600*6, # 6h
        memory = 20 # GB
    shell:
        """
        nice python scripts/evaluate_module_mapping_across_runs.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --output_file={output} \
                    --algorithms={params.algorithms} \
                    --iterations={params.iterations} \
                    --n_components={params.n_components}
        """
        
        
rule evaluate_module_mapping_robustness:
    input:
        os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'), # not used (linker)
        S_mean = os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S.tsv.gz'),
        S_std = os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S_std.tsv.gz')
    params:
        algorithm = '{algorithm}',
        n_samples = 100
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-module_mapping_robustness.tsv.gz')
    resources:
        runtime = 3600*6, # 6h
        memory = 20 # GB
    shell:
        """
        nice python scripts/evaluate_module_mapping_robustness.py \
                    --S_mean_file={input.S_mean} \
                    --S_std_file={input.S_std} \
                    --output_file={output} \
                    --algorithm={params.algorithm} \
                    --n_samples={params.n_samples} 
        """

        
rule combine_module_mapping_robustness:
    input:
        [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-module_mapping_robustness.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') 
         for algorithm in ['icasso','robustica_pca']]
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_robustness.tsv.gz')
    resources:
        runtime = 3600*1, # 6h
        memory = 5 # GB
    run:
        import pandas as pd
        df = pd.concat([pd.read_table(f) for f in input])
        df.to_csv(output[0], sep='\t', compression='gzip', index=False)
    
    
rule merge_results_across_datasets:
    input:
        performance = [os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz').format(dataset=dataset) for dataset in DATASETS],
        clustering = [os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz').format(dataset=dataset) for dataset in DATASETS],
        mapping_eval = [os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz').format(dataset=dataset) for dataset in DATASETS],
        mapping_rob = [os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_robustness.tsv.gz').format(dataset=dataset) for dataset in DATASETS],
        S_means = [os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_mean.tsv.gz').format(dataset=dataset) for dataset in DATASETS],
        S_stds = [os.path.join(RESULTS_DIR,'files','{dataset}','summary_S_std.tsv.gz').format(dataset=dataset) for dataset in DATASETS]
    output:
        performance = os.path.join(RESULTS_DIR,'files','merged_clustering_performance_evaluation.tsv.gz'),
        clustering = os.path.join(RESULTS_DIR,'files','merged_clustering_info.tsv.gz'),
        mapping_eval = os.path.join(RESULTS_DIR,'files','merged_module_mapping_evaluation.tsv.gz'),
        mapping_rob = os.path.join(RESULTS_DIR,'files','merged_module_mapping_robustness.tsv.gz'),
        S_means = os.path.join(RESULTS_DIR,'files','merged_summary_S_mean.tsv.gz'),
        S_stds = os.path.join(RESULTS_DIR,'files','merged_summary_S_std.tsv.gz')
    run:
        import os
        import pandas as pd
        for key, filenames in input.items():
            print(key)
            dfs = []
            for filename in filenames:
                dataset = os.path.basename(os.path.dirname(filename))
                print(dataset)
                
                df = pd.read_table(filename)
                df["dataset"] = dataset
                
                dfs.append(df)
            
            dfs = pd.concat(dfs)
            dfs.to_csv(output[key], **SAVE_PARAMS)
        
        print('Done!')
        
        
rule figures_benchmark_sign_inference:
    input:
        performance_evaluation = os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),
        clustering_info = os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz'),
        mapping_eval = os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz'),
        mapping_robust = os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_robustness.tsv.gz'),
        S_means = formatted['S_means'],
        S_stds = formatted['S_stds'],
        A_means = formatted['A_means'],
        A_stds = formatted['A_stds']
    output:
        figs_dir = directory(os.path.join(RESULTS_DIR,'figures','{dataset}'))
    params:
        S_means = ','.join(formatted['S_means']),
        S_stds = ','.join(formatted['S_stds']),
        A_means = ','.join(formatted['A_means']),
        A_stds = ','.join(formatted['A_stds'])
    shell:
        """
        Rscript scripts/figures_benchmark_sign_inference.R \
                    --performance_evaluation_file={input.performance_evaluation} \
                    --clustering_info_file={input.clustering_info} \
                    --S_means_files={params.S_means} \
                    --S_stds_files={params.S_stds} \
                    --A_means_files={params.A_means} \
                    --A_stds_files={params.A_stds} \
                    --mapping_eval_file={input.mapping_eval} \
                    --mapping_robust_file={input.mapping_robust} \
                    --figs_dir={output}
        """
        
