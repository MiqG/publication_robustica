"""
Workflow purpose
----------------
Evaluate the performance impact of changing the algorithm.

Outline
-------
1. Cluster 100 ICA runs and cluster:
    - the default algorithm (Icasso): 
        1) Distance Matrix
        2) Agglomerative clustering
        3) Compute centroids
        
    - robustica without sign correction
        1) Agglomerative clustering
        2) Compute centroids
    
    - robustica
        1) Correct signs
        2) Agglomerative clustering
        3) Compute centroids
    
    - robustica + PCA
        1) Correct signs
        2) compress feature space: PCA
        3) Agglomerative clustering
        4) Compute centroids
        
2. make figures
"""

import os

##### VARIABLES #####
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
DATA_DIR = os.path.join(ROOT,'data')
RAW_DIR = os.path.join(DATA_DIR,'raw')
PREP_DIR = os.path.join(DATA_DIR,'prep')
RESULTS_DIR = os.path.join(ROOT,'results','benchmark_sign_inference')

ALGORITHMS = ['icasso','robustica_nosign','robustica','robustica_pca']
ITERATIONS = 100
DATASETS = ['Sastry2019']
N_COMPONENTS = {
    'Sastry2019': 100
}

##### RULES #####
rule all:
    input:
        # evaluate performance
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),dataset=DATASETS),
        # evaluate module mapping
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz'),dataset=DATASETS),
        
        # make figures
        expand(os.path.join(RESULTS_DIR,'figures','{dataset}'),dataset=DATASETS)
        
        
rule evaluate_performance:
    input:
        S = os.path.join(PREP_DIR,'ica_runs','{dataset}','S.pickle.gz'),
        A = os.path.join(PREP_DIR,'ica_runs','{dataset}','A.pickle.gz'),
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz')
    params:
        algorithms = ','.join(ALGORITHMS),
        iterations = ITERATIONS
    shell:
        """
        python scripts/evaluate_performance.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --output_file={output} \
                    --iterations={params.iterations} \
                    --algorithms={params.algorithms}
        """

        
rule evaluate_module_mapping:
    input:
        S = os.path.join(PREP_DIR,'ica_runs','{dataset}','S.pickle.gz'),
        A = os.path.join(PREP_DIR,'ica_runs','{dataset}','A.pickle.gz'),
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz')
    params:
        algorithms = ','.join(ALGORITHMS),
        iterations = ITERATIONS,
        n_components = lambda wildcards: N_COMPONENTS[wildcards.dataset]
    shell:
        """
        python scripts/evaluate_module_mapping.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --output_file={output} \
                    --algorithms={params.algorithms} \
                    --iterations={params.iterations} \
                    --n_components={params.n_components}
        """
        
        
formatted = {
    'S_means' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'S_stds' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-S_std.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'A_means' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-A.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS],
    'A_stds' : [os.path.join(RESULTS_DIR,'files','{dataset}','{algorithm}-A_std.tsv.gz').format(algorithm=algorithm, dataset='{dataset}') for algorithm in ALGORITHMS]
}
rule figures_benchmark_sign_inference:
    input:
        performance_evaluation = os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),
        clustering_info = os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz'),
        mapping_eval = os.path.join(RESULTS_DIR,'files','{dataset}','module_mapping_evaluation.tsv.gz'),
        S_means = formatted['S_means'],
        S_stds = formatted['S_stds'],
        A_means = formatted['A_means'],
        A_stds = formatted['A_stds']
    output:
        figs_dir = directory(os.path.join(RESULTS_DIR,'figures','{dataset}'))
    params:
        S_means = ','.join(formatted['S_means']),
        S_stds = ','.join(formatted['S_stds']),
        A_means = ','.join(formatted['A_means']),
        A_stds = ','.join(formatted['A_stds'])
    shell:
        """
        Rscript scripts/figures_benchmark_sign_inference.R \
                    --performance_evaluation_file={input.performance_evaluation} \
                    --clustering_info_file={input.clustering_info} \
                    --S_means_files={params.S_means} \
                    --S_stds_files={params.S_stds} \
                    --A_means_files={params.A_means} \
                    --A_stds_files={params.A_stds} \
                    --mapping_eval_file={input.mapping_eval} \
                    --figs_dir={output}
        """
        