"""
Workflow purpose
----------------
Evaluate the performance impact of changing the algorithm.

Outline
-------
1. Compute ICA 100 times with a sample dataset with default parameters using:
        1) iterate ICAs (common for all)
    - the default algorithm (Icasso): 
        2) Distance Matrix
        3) Agglomerative clustering
        4) Compute centroids (correcting sign!)
    - robustica
        2) Correct signs
        3) Agglomerative clustering
        4) Compute centroids
    - robustica + PCA
        2) Correct signs
        3) compress feature space: PCA
        4) Agglomerative clustering
        5) Compute centroids
        
2. make figures
"""

import os

##### VARIABLES #####
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
DATA_DIR = os.path.join(ROOT,'data')
RAW_DIR = os.path.join(DATA_DIR,'raw')
PREP_DIR = os.path.join(DATA_DIR,'prep')
RESULTS_DIR = os.path.join(ROOT,'results','benchmark_performance')

ALGORITHMS = ['icasso','robustica_nosign','robustica','robustica_pca']
ITERATIONS = 100
DATASETS = ['Sastry2019']
N_COMPONENTS = {
    'Sastry2019': 100
}

##### RULES #####
rule all:
    input:
        # evaluate performance
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),dataset=DATASETS),
        
        # make figures
        expand(os.path.join(RESULTS_DIR,'figures','{dataset}'),dataset=DATASETS)
        
        
rule evaluate_performance:
    input:
        S = os.path.join(PREP_DIR,'ica_iterations','benchmark_data','{dataset}','S.pickle'),
        A = os.path.join(PREP_DIR,'ica_iterations','benchmark_data','{dataset}','A.pickle'),
        S_true = os.path.join(PREP_DIR,'benchmark_data','{dataset}','S.tsv.gz'),
        A_true = os.path.join(PREP_DIR,'benchmark_data','{dataset}','A.tsv.gz')
    output:
        os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz')
    params:
        algorithms = ','.join(ALGORITHMS),
        iterations = ITERATIONS
    shell:
        """
        python scripts/evaluate_performance.py \
                    --S_all_file={input.S} \
                    --A_all_file={input.A} \
                    --S_true_file={input.S_true} \
                    --A_true_file={input.A_true} \
                    --output_file={output} \
                    --iterations={params.iterations} \
                    --algorithms={params.algorithms}
        """


rule figures_benchmark_performance:
    input:
        performance_evaluation = os.path.join(RESULTS_DIR,'files','{dataset}','performance_evaluation.tsv.gz'),
        clustering_info = os.path.join(RESULTS_DIR,'files','{dataset}','clustering_info.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'figures','{dataset}'))
    shell:
        """
        Rscript scripts/figures_benchmark_performance.R \
                    --performance_evaluation_file={input.performance_evaluation} \
                    --clustering_info_file={input.clustering_info} \
                    --figs_dir={output}
        """
        